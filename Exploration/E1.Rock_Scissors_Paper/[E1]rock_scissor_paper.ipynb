{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기 + Resize 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PIL 라이브러리를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data Resize 하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 가위:0, 바위:1, 보:2로 트레이닝 셋 라벨링하기. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 9300 입니다.\n",
      "x_train shape: (9300, 28, 28, 3)\n",
      "y_train shape: (9300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=9300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"import numpy as np\" 요 코드는 어디에 넣어야 할까?? 맨 처음 PIL라이브러리를 불러올때 같이 불러오면 안될까? 라는 질문이 생겼다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터를 불러 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[8000])\n",
    "print('라벨: ', y_train[8000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 테스트 셋을 라벨링하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300 # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/test_scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/test_rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/test_paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 딥러닝 네트워크 설계, 훈련, 테스트까지~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 225,610\n",
      "Trainable params: 225,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "291/291 [==============================] - 4s 13ms/step - loss: 2.6968 - accuracy: 0.5549\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.7816\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.3255 - accuracy: 0.8749\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.9105\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9501\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9653\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9571\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.9608\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9767\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9897\n",
      "10/10 - 2s - loss: 0.8262 - accuracy: 0.8000\n",
      "test_loss: 0.8262317776679993 \n",
      "test_accuracy: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=128\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "형편없는 점수구만ㅋㅋㅋ 흠... 내가 생각하기에는 데이터가 좀 허술한 것 같아... 데이터를 바꿔보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 트레이닝 데이터를 바꾸자. (오버피팅 해소 시도)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 트레이닝셋 새로 라벨링하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train_final)의 이미지 개수는 6000 입니다.\n",
      "x_train_final shape: (6000, 28, 28, 3)\n",
      "y_train shape: (6000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=6000   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/final_scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/final_rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/final_paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train_final)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train_final, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train_final/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train_final shape: {}\".format(x_train_final.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 제발.... 제발......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 225,610\n",
      "Trainable params: 225,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 1.8907 - accuracy: 0.8877\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.9998\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 5.0361e-04 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.9082e-04 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.0183e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 6.8684e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 4.3858e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 2.8213e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 2.0462e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.4122e-05 - accuracy: 1.0000\n",
      "10/10 - 0s - loss: 0.0845 - accuracy: 0.9867\n",
      "test_loss: 0.08446872234344482 \n",
      "test_accuracy: 0.9866666793823242\n"
     ]
    }
   ],
   "source": [
    "#바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=128\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_final, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 느낀점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단순히, 데이터가 많아야 좋은 점수가 나올 거 같아서 많이 모으는 것에 집중했었다. 역시나 그렇게 모은 데이터의 질이 좋지 않았다. 알아 볼 수 없는 데이터들이 많았고, 그 데이터들로 학습을 시키니 좋은 결과가 나올리 없었다. 하이퍼 파라미터들을 조정해봐도 결과가 좋아지지 않았다. \n",
    "#### 결국, 트레이닝 데이터를 질 좋은 것으로 바꾸자는 결론을 내렸다. 그렇게 바꾸었더니 결과가 100점일 정도로 좋은 결과가 나왔다. \n",
    "#### 이번 프로젝트로 느낀 점은 데이터의 질이 굉장히 중요하다는 것이다.ㅎㅎ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
